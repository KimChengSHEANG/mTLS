{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datapane\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- fix path --\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "from source.resources import *\n",
    "from source.metrics import *\n",
    "from source.helper import *\n",
    "from source.preprocessor import *\n",
    "from source.constants import *\n",
    "import pandas as pd \n",
    "import datapane as dp \n",
    "from nltk import word_tokenize\n",
    "from functools import lru_cache\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json \n",
    "\n",
    "current_dir = Path('.')\n",
    "from IPython.display import display \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate reports for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_experiments(lang):\n",
    "    dirs = EXP_DIR.glob('exp_*')\n",
    "    dirs = sorted(list(dirs), key=lambda x: str(x).split('/')[-1])\n",
    "    for dir in dirs:\n",
    "        dirname = dir.name\n",
    "        print(dirname)\n",
    "        for phase in ['test','valid']:\n",
    "            out_file = EXP_DIR / dirname / f'{lang}.{phase}.xlsx'\n",
    "            # if out_file.exists(): continue\n",
    "            all_exp = []\n",
    "            files = list(( EXP_DIR / dirname / 'outputs').glob(f'*tsar-{lang}.{phase}_*.csv'))\n",
    "            for file in files:\n",
    "                # scores_file = files[0] if files else None \n",
    "                if file:\n",
    "                    data = pd.read_csv(file)\n",
    "                    params_file = EXP_DIR / dirname / 'params.json'\n",
    "                    if not params_file.exists(): continue\n",
    "                    json_data = json.load(params_file.open('r')) \n",
    "                    # lang = scores_file.name.split('-')[1].split('_')[0]\n",
    "                    # one_exp = {'exp_dir': dirname, 'file': file.name, 'lang': lang, 'model_name':json_data['model_name']}\n",
    "                    tokens = str(file.name).split(phase)[1].replace('.csv', '').strip('_')\n",
    "                    one_exp = {'exp_dir': dirname, 'lang': lang, 'model_name':json_data['model_name'], 'file':file.name, 'tokens': tokens }\n",
    "                    for key in data:\n",
    "                        one_exp[key] = float(data[key][0])/100\n",
    "                    # break\n",
    "                    all_exp.append(one_exp)\n",
    "            if all_exp:\n",
    "                df = pd.DataFrame(all_exp)\n",
    "                df.to_excel(out_file)\n",
    "                # dpdf = dp.DataTable(df)\n",
    "                # display(dpdf)\n",
    "    \n",
    "for lang in ['en', 'es', 'pt']:\n",
    "    display_experiments(lang)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display report for an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_experiments(lang):\n",
    "    # dirname = 'exp_1679856760224750-en-nocan-notokens'\n",
    "    dirname = get_last_experiment_dir().name\n",
    "    for phase in ['test','valid']:\n",
    "        # if out_file.exists(): continue\n",
    "        all_exp = []\n",
    "        files = list(( EXP_DIR / dirname / 'outputs').glob(f'*.{phase}_*.csv'))\n",
    "        out_file = EXP_DIR / dirname / f'{lang}.{phase}.xlsx'\n",
    "        for file in files:\n",
    "            # scores_file = files[0] if files else None \n",
    "            if file:\n",
    "                data = pd.read_csv(file)\n",
    "                params_file = EXP_DIR / dirname / 'params.json'\n",
    "                json_data = json.load(params_file.open('r')) \n",
    "                # lang = scores_file.name.split('-')[1].split('_')[0]\n",
    "                tokens = str(file.name).split(phase)[1].replace('.csv', '').strip('_')\n",
    "                one_exp = {'exp_dir': dirname, 'lang': lang, 'model_name':json_data['model_name'], 'file':file.name, 'tokens': tokens }\n",
    "                for key in data:\n",
    "                    one_exp[key] = float(data[key][0])/100\n",
    "                # break\n",
    "                all_exp.append(one_exp)\n",
    "        if all_exp:\n",
    "            df = pd.DataFrame(all_exp)\n",
    "            df.to_excel(out_file)\n",
    "            dpdf = dp.DataTable(df)\n",
    "            display(dpdf)\n",
    "    \n",
    "for lang in ['en', 'es', 'pt']:\n",
    "    display_experiments(lang)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BenchLS, LexMTurk, NNSeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_experiments():\n",
    "    dirname = 'exp_1680081247342939-tsar-en-for-conls'\n",
    "    # dirname = get_last_experiment_dir().name\n",
    "    for dataset in ['benchls', 'lexmturk', 'NNSeval', 'tsar-en']:\n",
    "        # if out_file.exists(): continue\n",
    "        all_exp = []\n",
    "        files = list(( EXP_DIR / dirname / 'outputs').glob(f'scores_{dataset}*.csv'))\n",
    "        # print(list(files))\n",
    "        out_file = EXP_DIR / dirname / f'{dataset}.xlsx'\n",
    "        for file in files:\n",
    "            # scores_file = files[0] if files else None \n",
    "            if file:\n",
    "                data = pd.read_csv(file)\n",
    "                params_file = EXP_DIR / dirname / 'params.json'\n",
    "                json_data = json.load(params_file.open('r')) \n",
    "                # lang = scores_file.name.split('-')[1].split('_')[0]\n",
    "                tokens = '_'.join(file.name.split('_')[2:]).replace('.csv', '')\n",
    "                # print(tokens)\n",
    "                \n",
    "                one_exp = {'exp_dir': dirname, 'model_name':json_data['model_name'], 'file':file.name, 'tokens': tokens }\n",
    "                for key in data:\n",
    "                    one_exp[key] = float(data[key][0])/100\n",
    "                # break\n",
    "                all_exp.append(one_exp)\n",
    "        if all_exp:\n",
    "            df = pd.DataFrame(all_exp)\n",
    "            df.to_excel(out_file)\n",
    "            dpdf = dp.DataTable(df)\n",
    "            display(dpdf)\n",
    "    \n",
    "display_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "774dfef66576c1bc5f6c5092ce4ace6ecc473aab9c3e9d99e780abb421ef3888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
